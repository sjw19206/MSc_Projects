{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network predicts quality scores for the individual repetitions for Exercise 1 - Deep Squat. The input to the network are the raw measurement data with 117 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and functions\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "import csv\n",
    "import os,random\n",
    "\n",
    "# The code is run on a CPU\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, LSTM, Dense, Dropout, Activation, Flatten, concatenate, UpSampling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import *\n",
    "from keras.layers import Lambda\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "import datetime\n",
    "now = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 240  # number of timesteps\n",
    "nr = 90   # number of repetitions\n",
    "n_dim = 117  # dimension of the data sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'DataViconLoad'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mDataViconLoad\u001b[39;00m   \u001b[38;5;66;03m# Import the data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m Correct_data, Correct_label, Incorrect_data, Incorrect_label \u001b[38;5;241m=\u001b[39m DataViconLoad\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Print the size of the data \u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'DataViconLoad'"
     ]
    }
   ],
   "source": [
    "import DataViconLoad   # Import the data\n",
    "Correct_data, Correct_label, Incorrect_data, Incorrect_label = DataViconLoad.load_data()\n",
    "\n",
    "# Print the size of the data \n",
    "print(Correct_data.shape, 'correct sequences')\n",
    "print(Correct_label.shape, 'correct labels')\n",
    "print(Incorrect_data.shape, 'incorrect sequences')\n",
    "print(Incorrect_label.shape, 'incorrect labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "# Training set: 60%\n",
    "# Testing set: 20%\n",
    "# Validation set: 20%\n",
    "\n",
    "# Sample random indices\n",
    "trainidx1 = random.sample(range(0,Correct_data.shape[0]),int(nr*0.6))\n",
    "trainidx2 = random.sample(range(0,Incorrect_data.shape[0]),int(nr*0.6))\n",
    "\n",
    "tempidx1 = np.setdiff1d(np.arange(0,nr,1),trainidx1)\n",
    "tempidx2 = np.setdiff1d(np.arange(0,nr,1),trainidx2)\n",
    "\n",
    "valididx1 = tempidx1[::2] \n",
    "valididx2 = tempidx1[1::2]\n",
    "\n",
    "testidx1 = tempidx2[1::2]\n",
    "testidx2 = tempidx2[::2]\n",
    "\n",
    "\n",
    "# Training set: data and labels\n",
    "train_x = np.concatenate((Correct_data[trainidx1,:,:],Incorrect_data[trainidx2,:,:]))\n",
    "print(train_x.shape, 'training data')\n",
    "train_y = np.concatenate((np.squeeze(Correct_label[trainidx1]),np.squeeze(Incorrect_label[trainidx2])))\n",
    "print(train_y.shape, 'training labels')\n",
    "\n",
    "\n",
    "# Testing set: data and labels\n",
    "test_x = np.concatenate((Correct_data[testidx1,:,:],Incorrect_data[testidx2,:,:]))\n",
    "print(test_x.shape, 'testing data')\n",
    "test_y = np.concatenate((np.squeeze(Correct_label[testidx1]),np.squeeze(Incorrect_label[testidx2])))\n",
    "print(test_y.shape, 'testing labels')\n",
    "\n",
    "# Validation set: data and labels\n",
    "valid_x = np.concatenate((Correct_data[valididx1,:,:],Incorrect_data[valididx2,:,:]))\n",
    "print(valid_x.shape, 'validation data')\n",
    "valid_y = np.concatenate((np.squeeze(Correct_label[valididx1]),np.squeeze(Incorrect_label[valididx2])))\n",
    "print(valid_y.shape, 'validation labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first and last sequence in the training and validation sets\n",
    "plt.figure(figsize = (14,4))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(train_x[0])\n",
    "plt.title('First Train Sequence')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(train_x[-1])\n",
    "plt.title('Last Train Sequence')\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(valid_x[0])\n",
    "plt.title('First Validation Sequence')\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(valid_x[-1])\n",
    "plt.title('Last Validation Sequence')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the data length by a factor of 2, 4, and 8 \n",
    "# The reduced sequences will be used as inputs to the temporal pyramid subnetwork\n",
    "train_x_2 = np.zeros((train_x.shape[0], int(train_x.shape[1]/2), train_x.shape[2]))\n",
    "valid_x_2 = np.zeros(train_x_2.shape)\n",
    "test_x_2 = np.zeros(train_x_2.shape)\n",
    "\n",
    "train_x_4 = np.zeros((train_x.shape[0], int(train_x.shape[1]/4), train_x.shape[2]))\n",
    "valid_x_4 = np.zeros(train_x_4.shape)\n",
    "test_x_4 = np.zeros(train_x_4.shape)\n",
    "\n",
    "train_x_8 = np.zeros((train_x.shape[0], int(train_x.shape[1]/8), train_x.shape[2]))\n",
    "valid_x_8 = np.zeros(train_x_8.shape)\n",
    "test_x_8 = np.zeros(train_x_8.shape)\n",
    "\n",
    "train_x_2 = train_x[:,::2,:]\n",
    "valid_x_2 = valid_x[:,::2,:]\n",
    "test_x_2 = test_x[:,::2,:]\n",
    "\n",
    "train_x_4 = train_x[:,::4,:]\n",
    "valid_x_4 = valid_x[:,::4,:]\n",
    "test_x_4 = test_x[:,::4,:]\n",
    "\n",
    "train_x_8 = train_x[:,::8,:]\n",
    "valid_x_8 = valid_x[:,::8,:]\n",
    "test_x_8 = test_x[:,::8,:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to re-order the 117 dimensional skeleton data from the Vicon optical tracker into trunk, left arm, right arm, left leg and right leg\n",
    "def reorder_data(x):\n",
    "    X_trunk = np.zeros((x.shape[0],x.shape[1],12))\n",
    "    X_left_arm = np.zeros((x.shape[0],x.shape[1],18))\n",
    "    X_right_arm = np.zeros((x.shape[0],x.shape[1],18))\n",
    "    X_left_leg = np.zeros((x.shape[0],x.shape[1],21))\n",
    "    X_right_leg = np.zeros((x.shape[0],x.shape[1],21))\n",
    "    X_trunk =  np.concatenate((x[:,:,15:18], x[:,:,18:21], x[:,:,24:27], x[:,:,27:30]), axis = 2)\n",
    "    X_left_arm = np.concatenate((x[:,:,81:84], x[:,:,87:90], x[:,:,93:96], x[:,:,99:102], x[:,:,105:108], x[:,:,111:114]), axis = 2)\n",
    "    X_right_arm = np.concatenate((x[:,:,84:87], x[:,:,90:93], x[:,:,96:99], x[:,:,102:105], x[:,:,108:111], x[:,:,114:117]), axis = 2)  \n",
    "    X_left_leg = np.concatenate((x[:,:,33:36], x[:,:,39:42], x[:,:,45:48], x[:,:,51:54], x[:,:,57:60], x[:,:,63:66], x[:,:,69:72]), axis = 2)\n",
    "    X_right_leg = np.concatenate((x[:,:,36:39], x[:,:,42:45], x[:,:,48:51], x[:,:,54:57], x[:,:,60:63], x[:,:,66:69], x[:,:,72:75]), axis = 2)\n",
    "    x_segmented = np.concatenate((X_trunk, X_right_arm, X_left_arm, X_right_leg, X_left_leg),axis = -1)\n",
    "    return x_segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the data dimensions to correspond to the five body parts\n",
    "trainx =  reorder_data(train_x)\n",
    "validx =  reorder_data(valid_x)\n",
    "testx =  reorder_data(test_x)\n",
    "\n",
    "trainx_2 =  reorder_data(train_x_2)\n",
    "validx_2 =  reorder_data(valid_x_2)\n",
    "testx_2 =  reorder_data(test_x_2)\n",
    "\n",
    "trainx_4 =  reorder_data(train_x_4)\n",
    "validx_4 =  reorder_data(valid_x_4)\n",
    "testx_4 =  reorder_data(test_x_4)\n",
    "\n",
    "trainx_8 =  reorder_data(train_x_8)\n",
    "validx_8 =  reorder_data(valid_x_8)\n",
    "testx_8 =  reorder_data(test_x_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a multibranch convolutional Inception-like block\n",
    "def MultiBranchConv1D(input, filters1, kernel_size1, strides1, strides2):\n",
    "    print('shape of input: ', input.shape)\n",
    "    x1 = Conv1D(filters=filters1, kernel_size=kernel_size1+2, strides=strides1, padding='same', activation='relu')(input)\n",
    "    x1 = Dropout(0.25)(x1)\n",
    "    x2 = Conv1D(filters=filters1, kernel_size=kernel_size1+6, strides=strides1, padding='same', activation='relu')(input)\n",
    "    x2 = Dropout(0.25)(x2)\n",
    "    x3 = Conv1D(filters=filters1, kernel_size=kernel_size1+12, strides=strides1, padding='same', activation='relu')(input)\n",
    "    x3 = Dropout(0.25)(x3)\n",
    "    y1 = concatenate([x1, x2, x3], axis=-1)\n",
    "\n",
    "    x4 = Conv1D(filters=filters1, kernel_size=kernel_size1, strides=strides2, padding='same', activation='relu')(y1)\n",
    "    x4 = Dropout(0.25)(x4)\n",
    "    x5 = Conv1D(filters=filters1, kernel_size=kernel_size1+2, strides=strides2, padding='same', activation='relu')(y1)\n",
    "    x5 = Dropout(0.25)(x5)\n",
    "    x6 = Conv1D(filters=filters1, kernel_size=kernel_size1+4, strides=strides2, padding='same', activation='relu')(y1)\n",
    "    x6 = Dropout(0.25)(x6)\n",
    "    x = concatenate([x4, x5, x6], axis=-1)\n",
    "    print('shape of x: ', x.shape)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a temporal pyramid network\n",
    "def TempPyramid(input_f, input_2, input_4, input_8, seq_len, n_dims):\n",
    "    \n",
    "    #### Full scale sequences\n",
    "    conv1 = MultiBranchConv1D(input_f, 64, 3, 2, 2)\n",
    "    \n",
    "    #### Half scale sequences\n",
    "    conv2 = MultiBranchConv1D(input_2, 64, 3, 2, 1)\n",
    "\n",
    "    #### Quarter scale sequences\n",
    "    conv3 = MultiBranchConv1D(input_4, 64, 3, 1, 1)\n",
    "\n",
    "    #### Eighth scale sequences\n",
    "    conv4 = MultiBranchConv1D(input_8, 64, 3, 1, 1)\n",
    "    upsample1 = UpSampling1D(size = 2)(conv4)\n",
    "\n",
    "    #### Recurrent layers\n",
    "    x = concatenate([conv1, conv2, conv3, upsample1], axis=-1)\n",
    "    return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 90 # dimension after segmenting the data into body parts\n",
    "n_dim1 = 12 # trunk dimension\n",
    "n_dim2 = 18 # arms dimension\n",
    "n_dim3 = 21 # legs dimension\n",
    "\n",
    "# Build the model ...\n",
    "\n",
    "#### Full scale sequences\n",
    "seq_input = Input(shape = (timesteps, n_dim), name = 'full_scale')\n",
    "\n",
    "seq_input_trunk = Lambda(lambda x: x[:, :, 0:12])(seq_input)\n",
    "seq_input_left_arm = Lambda(lambda x: x[:, :, 12:30])(seq_input)\n",
    "seq_input_right_arm = Lambda(lambda x: x[:, :, 30:48])(seq_input)\n",
    "seq_input_left_leg = Lambda(lambda x: x[:, :, 48:69])(seq_input)\n",
    "seq_input_right_leg = Lambda(lambda x: x[:, :, 69:90])(seq_input)\n",
    "\n",
    "#### Half scale sequences\n",
    "seq_input_2 = Input(shape=(int(timesteps/2), n_dim), name='half_scale')\n",
    "\n",
    "seq_input_trunk_2 = Lambda(lambda x: x[:, :, 0:12])(seq_input_2)\n",
    "seq_input_left_arm_2 = Lambda(lambda x: x[:, :, 12:30])(seq_input_2)\n",
    "seq_input_right_arm_2 = Lambda(lambda x: x[:, :, 30:48])(seq_input_2)\n",
    "seq_input_left_leg_2 = Lambda(lambda x: x[:, :, 48:69])(seq_input_2)\n",
    "seq_input_right_leg_2 = Lambda(lambda x: x[:, :, 69:90])(seq_input_2)\n",
    "\n",
    "#### Quarter scale sequences\n",
    "seq_input_4 = Input(shape=(int(timesteps/4), n_dim), name='quarter_scale')\n",
    "\n",
    "seq_input_trunk_4 = Lambda(lambda x: x[:, :, 0:12])(seq_input_4)\n",
    "seq_input_left_arm_4 = Lambda(lambda x: x[:, :, 12:30])(seq_input_4)\n",
    "seq_input_right_arm_4 = Lambda(lambda x: x[:, :, 30:48])(seq_input_4)\n",
    "seq_input_left_leg_4 = Lambda(lambda x: x[:, :, 48:69])(seq_input_4)\n",
    "seq_input_right_leg_4 = Lambda(lambda x: x[:, :, 69:90])(seq_input_4)\n",
    "\n",
    "#### Eighth scale sequences\n",
    "seq_input_8 = Input(shape=(int(timesteps/8), n_dim), name='eighth_scale')\n",
    "\n",
    "seq_input_trunk_8 = Lambda(lambda x: x[:, :, 0:12])(seq_input_8)\n",
    "seq_input_left_arm_8 = Lambda(lambda x: x[:, :, 12:30])(seq_input_8)\n",
    "seq_input_right_arm_8 = Lambda(lambda x: x[:, :, 30:48])(seq_input_8)\n",
    "seq_input_left_leg_8 = Lambda(lambda x: x[:, :, 48:69])(seq_input_8)\n",
    "seq_input_right_leg_8 = Lambda(lambda x: x[:, :, 69:90])(seq_input_8)\n",
    "\n",
    "concat_trunk = TempPyramid(seq_input_trunk, seq_input_trunk_2, seq_input_trunk_4, seq_input_trunk_8, timesteps, n_dim1)\n",
    "concat_left_arm = TempPyramid(seq_input_left_arm, seq_input_left_arm_2, seq_input_left_arm_4, seq_input_left_arm_8, timesteps, n_dim2)\n",
    "concat_right_arm = TempPyramid(seq_input_right_arm, seq_input_right_arm_2, seq_input_right_arm_4, seq_input_right_arm_8, timesteps, n_dim2)\n",
    "concat_left_leg = TempPyramid(seq_input_left_leg, seq_input_left_leg_2, seq_input_left_leg_4, seq_input_left_leg_8, timesteps, n_dim3)\n",
    "concat_right_leg = TempPyramid(seq_input_right_leg, seq_input_right_leg_2, seq_input_right_leg_4, seq_input_right_leg_8, timesteps, n_dim3)\n",
    "\n",
    "\n",
    "print('concat_trunk: ', concat_trunk.shape)\n",
    "print('concat_left_arm: ', concat_left_arm.shape)\n",
    "print('concat_right_arm: ', concat_right_arm.shape)\n",
    "print('concat_left_leg: ', concat_left_leg.shape)\n",
    "print('concat_right_leg: ', concat_right_leg.shape)\n",
    "\n",
    "concat = concatenate([concat_trunk, concat_left_arm, concat_right_arm, concat_left_leg, concat_right_leg], axis=-1)\n",
    "\n",
    "rec = LSTM(80, return_sequences=True)(concat)\n",
    "rec1 = LSTM(40, return_sequences=True)(rec)\n",
    "rec1 = LSTM(40, return_sequences=True)(rec1)\n",
    "rec2 = LSTM(80)(rec1)\n",
    "\n",
    "out = Dense(1, activation = 'sigmoid')(rec2)\n",
    "\n",
    "model = Model(inputs=[seq_input, seq_input_2, seq_input_4, seq_input_8], outputs=out)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer= Adam(learning_rate=0.0001)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = now()\n",
    "    \n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 25)\n",
    "\n",
    "history = model.fit([trainx, trainx_2, trainx_4, trainx_8], train_y, batch_size=10, epochs=500, verbose=1, \n",
    "                validation_data=([validx, validx_2, validx_4, validx_8], valid_y), callbacks = [early_stopping])\n",
    "\n",
    "print('Training time: %s' % (now() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'], 'b', label = 'Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.plot(history.history['val_loss'], 'r', label = 'Validation Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Print the minimum loss\n",
    "print(\"Training loss\", np.min(history.history['loss']))\n",
    "print(\"Validation loss\",np.min(history.history['val_loss']))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the prediction of the model for the training and validation sets\n",
    "pred_train = model.predict([trainx, trainx_2, trainx_4, trainx_8])\n",
    "\n",
    "pred_test = model.predict([testx, testx_2, testx_4, testx_8])\n",
    "\n",
    "plt.figure(figsize = (8,8))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(pred_train,'s', color='red', label='Prediction', linestyle='None', alpha = 0.5, markersize=6)\n",
    "plt.plot(train_y,'o', color='green',label='Quality Score', alpha = 0.4, markersize=6)\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.title('Training Set',fontsize=18)\n",
    "plt.xlabel('Sequence Number',fontsize=16)\n",
    "plt.ylabel('Quality Scale',fontsize=16)\n",
    "plt.legend(loc=3, prop={'size':14}) # loc:position\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(pred_test,'s', color='red', label='Prediction', linestyle='None', alpha = 0.5, markersize=6)\n",
    "plt.plot(test_y,'o', color='green',label='Quality Score', alpha = 0.4, markersize=6)\n",
    "plt.title('Testing Set',fontsize=18)\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.xlabel('Sequence Number',fontsize=16)\n",
    "plt.ylabel('Quality Scale',fontsize=16)\n",
    "plt.legend(loc=3, prop={'size':14}) # loc:position\n",
    "plt.tight_layout()\n",
    "plt.savefig('SpatioTemporal_Split.png', dpi=350)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cumulative deviation and rms deviation for the validation set\n",
    "test_dev = abs(np.squeeze(pred_test)-test_y)\n",
    "# Cumulative deviation\n",
    "mean_abs_dev = np.mean(test_dev)\n",
    "# RMS deviation\n",
    "rms_dev = sqrt(mean_squared_error(pred_test, test_y))\n",
    "print('Mean absolute deviation:', mean_abs_dev)\n",
    "print('RMS deviation:', rms_dev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
